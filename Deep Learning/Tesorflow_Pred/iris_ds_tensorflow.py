# -*- coding: utf-8 -*-
"""Iris DS TensorFlow.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z8a7f4cZ2nogsElPo3zQ_GBQNY8GvzAW
"""

import tensorflow as tf
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.metrics import accuracy_score
import numpy as np

# Load dataset
df = pd.read_csv('https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv')

# Convert target labels to numbers
df['variety'] = df['variety'].replace({'Setosa': 0, 'Versicolor': 1, 'Virginica': 2})

# One-hot encoding
encoder = OneHotEncoder()
#y = encoder.fit_transform(df[['variety']].toarry())  # Convert labels to one-hot
y = encoder.fit_transform(df[['variety']]).toarray()  # Convert to dense array


# Split dataset
x = df.drop('variety', axis=1)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=41)

# Define the model
model = Sequential([
    Dense(32, activation='relu', input_dim=len(x_train.columns)),
    Dense(64, activation='relu'),#'activation = 'relu' signifies using the Rectified Linear Unit (ReLU) activation functionvc
    Dense(3, activation='softmax')  # 3 output neurons for 3 classes
])

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=200, batch_size=32, verbose=1)

# Predict and evaluate
y_hat = model.predict(x_test)
y_pred = np.argmax(y_hat, axis=1)  # Convert probabilities to class labels
y_true = np.argmax(y_test, axis=1)  # Convert one-hot labels back to class labels

# Calculate accuracy
accuracy = accuracy_score(y_true, y_pred)
print("Model Accuracy:", accuracy)

